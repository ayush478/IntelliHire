# ðŸ§  AI Concepts Guide - From Absolute Basics to Interview Ready

> **A beginner-friendly explanation of AI concepts used in IntelliHire, with real examples from the project.**

---

## ðŸ“‹ Table of Contents

1. [What is AI? The Big Picture](#-1-what-is-ai-the-big-picture)
2. [Large Language Models (LLMs)](#-2-large-language-models-llms)
3. [Vector Embeddings](#-3-vector-embeddings)
4. [Vector Databases](#-4-vector-databases)
5. [RAG - Retrieval Augmented Generation](#-5-rag---retrieval-augmented-generation)
6. [Fuzzy String Matching](#-6-fuzzy-string-matching)
7. [AI Content Detection](#-7-ai-content-detection)
8. [How IntelliHire Uses These Concepts](#-8-how-intellihire-uses-these-concepts)
9. [Interview Q&A](#-9-interview-qa)
10. [Quick Reference](#-10-quick-reference)

---

## ðŸŒ 1. What is AI? The Big Picture

### The Simplest Definition

**Artificial Intelligence (AI)** is teaching computers to do tasks that normally require human intelligence:
- Understanding language
- Recognizing patterns
- Making decisions
- Learning from data

### AI Hierarchy - Understanding the Terms

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ARTIFICIAL INTELLIGENCE (AI)                  â”‚
â”‚           "Machines that can perform human-like tasks"           â”‚
â”‚                                                                  â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚              MACHINE LEARNING (ML)                       â”‚   â”‚
â”‚   â”‚     "AI that learns patterns from data automatically"    â”‚   â”‚
â”‚   â”‚                                                          â”‚   â”‚
â”‚   â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚   â”‚
â”‚   â”‚   â”‚            DEEP LEARNING (DL)                    â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   "ML using neural networks with many layers"    â”‚   â”‚   â”‚
â”‚   â”‚   â”‚                                                  â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”‚   LARGE LANGUAGE MODELS (LLMs)          â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”‚   "DL models trained on massive text"   â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”‚   Examples: GPT-4, Gemini, Claude       â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Analogy: Learning to Recognize Cats

| Approach | How It Works |
|----------|--------------|
| **Traditional Programming** | Write rules: "If has pointy ears AND whiskers AND furry â†’ cat" |
| **Machine Learning** | Show 10,000 cat photos, let the computer figure out the patterns |
| **Deep Learning** | Use neural networks to learn complex patterns (eyes, ears, body shape) |

**IntelliHire uses:** LLMs (Gemini) to understand resumes and job descriptions, plus similarity algorithms to match candidates.

---

## ðŸ¤– 2. Large Language Models (LLMs)

### What is an LLM?

An LLM is a type of AI trained on **billions** of text examples (books, websites, code) to understand and generate human language.

**Analogy:**
Imagine reading EVERY book ever written, EVERY website, EVERY document. After that, you'd be pretty good at:
- Writing in any style
- Answering questions
- Summarizing documents
- Extracting information

That's what an LLM does, but with computers.

### How LLMs Work (Simplified)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         LLM PROCESSING                          â”‚
â”‚                                                                  â”‚
â”‚  INPUT (Prompt)          PROCESSING              OUTPUT         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ "Parse this  â”‚â”€â”€â”€â”€â–ºâ”‚ Neural       â”‚â”€â”€â”€â”€â–ºâ”‚ {"name":     â”‚    â”‚
â”‚  â”‚  resume:     â”‚     â”‚ Network with â”‚     â”‚  "Jane",     â”‚    â”‚
â”‚  â”‚  Jane Smith  â”‚     â”‚ billions of  â”‚     â”‚  "skills":   â”‚    â”‚
â”‚  â”‚  Python dev" â”‚     â”‚ parameters   â”‚     â”‚  ["python"]} â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Key Concepts

| Term | Meaning | Example |
|------|---------|---------|
| **Prompt** | The instruction you give the LLM | "Extract skills from this resume" |
| **Token** | A chunk of text (roughly 4 characters) | "Hello" = 1 token, "Python developer" = 2 tokens |
| **Context Window** | How much text the model can "see" at once | Gemini: ~1 million tokens |
| **Temperature** | Creativity level (0 = deterministic, 1 = creative) | 0 for structured extraction |
| **Parameters** | Internal "knobs" the model has learned | GPT-4: ~1.8 trillion parameters |

### How IntelliHire Uses LLMs

```python
# From job_descriptions.py - Parsing a job description
JD_PROMPT = """
You are an expert HR analyst. Given a Job Description, return STRICT JSON:
{
  "title": string,
  "seniority": "junior" | "mid" | "senior" | ...,
  "required_skills": string[],
  "responsibilities": string[]
}
Only output JSON. No markdown. No commentary.
"""

# The LLM (Gemini) receives:
# 1. The prompt above (instructions)
# 2. The job description text (data)
# And returns structured JSON we can use in code
```

### Prompt Engineering Tips

```
1. BE SPECIFIC
   âŒ Bad:  "Parse this resume"
   âœ… Good: "Extract name, skills, and seniority level as JSON"

2. GIVE EXAMPLES
   "For 'John - Python dev', return: {name: 'John', skills: ['python']}"

3. SPECIFY OUTPUT FORMAT
   "Return ONLY valid JSON. No markdown. No extra text."

4. SET CONSTRAINTS
   "Skills should be lowercase. Max 50 skills."
```

---

## ðŸ“Š 3. Vector Embeddings

### What is a Vector?

**Vector = A list of numbers**

That's it! A vector is just an ordered list of numbers, like coordinates.

```
2D Vector (point on a map):     [3.5, 7.2]
3D Vector (point in space):     [3.5, 7.2, 1.8]
ML Vector (word meaning):       [0.23, -0.45, 0.78, ..., 0.12]  (hundreds of numbers)
```

### What is an Embedding?

**Embedding = Converting something (text, image, etc.) into a vector**

The magic: similar things get similar vectors!

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    TEXT TO VECTOR (EMBEDDING)                    â”‚
â”‚                                                                  â”‚
â”‚   "Python developer"  â”€â”€â†’  [0.82, 0.15, 0.93, -0.21, ...]       â”‚
â”‚   "Python programmer" â”€â”€â†’  [0.81, 0.16, 0.92, -0.20, ...]  â† Similar!
â”‚   "Java developer"    â”€â”€â†’  [0.55, 0.32, 0.71, -0.45, ...]       â”‚
â”‚   "Chef"              â”€â”€â†’  [-0.12, 0.88, -0.34, 0.67, ...]  â† Very different!
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### The Analogy: Words as Coordinates

Imagine a map where:
- **X-axis** = Technical skill
- **Y-axis** = Creativity

```
                     Creativity
                        â†‘
                        â”‚    ðŸŽ¨ Artist
                        â”‚
        ðŸ§‘â€ðŸ’» Software     â”‚         ðŸ“ Writer
           Engineer     â”‚
     â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Technical
                        â”‚
         ðŸ“Š Data        â”‚
           Scientist    â”‚
                        â”‚
```

**Embeddings do this in hundreds of dimensions!**

Each dimension might capture:
- Technical vs. creative
- Leadership vs. individual contributor
- Frontend vs. backend
- Years of experience indicator
- And hundreds more patterns...

### How Embeddings Are Created

```python
from sentence_transformers import SentenceTransformer

# Load a pre-trained embedding model
model = SentenceTransformer('all-MiniLM-L6-v2')

# Convert text to vector
resume_text = "Senior Python developer with 5 years experience in machine learning"
embedding = model.encode(resume_text)

# embedding is now a list of 384 numbers
print(len(embedding))  # 384
print(embedding[:5])   # [0.023, -0.156, 0.892, 0.234, -0.067]
```

### Why 384 (or 768, or 1536) Numbers?

Different models output different sizes:
- `all-MiniLM-L6-v2`: 384 dimensions (fast, good for similarity)
- `text-embedding-ada-002` (OpenAI): 1536 dimensions
- `BERT-base`: 768 dimensions

More dimensions = more nuance, but also more computation.

### Measuring Similarity: Cosine Similarity

**How do we compare two vectors?**

```
                Cosine Similarity
                
     Vector A â”€â”€â”€â”€â–º
                 Î¸  (angle between them)
     Vector B â”€â”€â”€â”€â”€â”€â”€â–º
     
     Similarity = cos(Î¸)
     
     cos(0Â°)  = 1.0   (identical direction = same meaning)
     cos(90Â°) = 0.0   (perpendicular = unrelated)
     cos(180Â°) = -1.0 (opposite = opposite meaning)
```

**Python implementation:**
```python
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity

# Two resume embeddings
resume_a = [0.82, 0.15, 0.93, -0.21]  # Python developer
resume_b = [0.81, 0.16, 0.92, -0.20]  # Another Python developer
resume_c = [-0.12, 0.88, -0.34, 0.67]  # Chef

# Calculate similarity (0 to 1 scale after normalization)
sim_ab = cosine_similarity([resume_a], [resume_b])[0][0]  # ~0.99 (very similar!)
sim_ac = cosine_similarity([resume_a], [resume_c])[0][0]  # ~0.12 (very different)
```

### IntelliHire Example: Matching Resumes to Jobs

```python
# Conceptual flow (if using embeddings)

# 1. Embed the job description
jd_text = "Looking for a Senior ML Engineer with Python and TensorFlow"
jd_embedding = model.encode(jd_text)

# 2. Embed each resume
resumes = [
    "5 years machine learning with Python, built recommendation systems",
    "Frontend developer with React and TypeScript experience",
    "Python data scientist with TensorFlow and PyTorch expertise"
]
resume_embeddings = [model.encode(r) for r in resumes]

# 3. Calculate similarities
for i, resume_emb in enumerate(resume_embeddings):
    similarity = cosine_similarity([jd_embedding], [resume_emb])[0][0]
    print(f"Resume {i+1}: {similarity:.2f}")

# Output:
# Resume 1: 0.87 (good match - ML + Python)
# Resume 2: 0.34 (poor match - wrong domain)
# Resume 3: 0.91 (excellent match - ML + TensorFlow)
```

---

## ðŸ—„ï¸ 4. Vector Databases

### What is a Vector Database?

A **vector database** is a database optimized for storing and searching vectors (embeddings).

**Regular Database:**
```sql
SELECT * FROM resumes WHERE skills LIKE '%python%'
-- Only finds exact word matches!
```

**Vector Database:**
```
Find resumes with embeddings similar to job_description_embedding
-- Finds semantically similar content!
```

### Why Do We Need Vector Databases?

**Problem:** You have 1 million resumes. Each one's embedding is 384 numbers. 

To find the most similar resume:
- Compare job embedding to ALL 1 million resume embeddings
- Calculate 1 million cosine similarities
- **Too slow!** (O(n) for each query)

**Solution:** Vector databases use special indexing (like HNSW) to search in milliseconds.

### Popular Vector Databases

| Database | Type | Best For |
|----------|------|----------|
| **Pinecone** | Managed cloud | Production, scaling |
| **Weaviate** | Open-source, cloud option | Full-featured, hybrid search |
| **Chroma** | Open-source | Local development, small projects |
| **Milvus** | Open-source | Large scale, on-premise |
| **pgvector** | PostgreSQL extension | If you already use Postgres |
| **MongoDB Atlas Vector Search** | MongoDB extension | If you already use MongoDB |

### How Vector Search Works (Simplified)

```
Traditional Search (Exact Match):
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Query: "Python developer"
â””â”€â”€ Search index for exact words
â””â”€â”€ Results: Documents containing "Python" AND "developer"

Vector Search (Semantic Similarity):
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Query: "Python developer"
â””â”€â”€ Convert to vector: [0.82, 0.15, 0.93, ...]
â””â”€â”€ Find nearest vectors in database
â””â”€â”€ Results include:
    - "Python programmer" (similar meaning!)
    - "Software engineer with Python" (related!)
    - "ML engineer using Python" (related!)
```

### ANN (Approximate Nearest Neighbors)

Vector databases don't check EVERY vector. They use clever algorithms:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  HNSW (Hierarchical Navigable Small World)       â”‚
â”‚                                                                  â”‚
â”‚  Instead of checking all 1 million vectors:                     â”‚
â”‚                                                                  â”‚
â”‚  1. Build a graph where similar vectors are connected            â”‚
â”‚  2. Start at a random point                                      â”‚
â”‚  3. Jump to neighbors that are closer to query                   â”‚
â”‚  4. Repeat until you find the closest                           â”‚
â”‚                                                                  â”‚
â”‚  Result: Find top 10 similar resumes in ~1ms instead of 10s!    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Example: Adding IntelliHire to a Vector Database

```python
# Hypothetical example using Chroma (a popular vector DB)

import chromadb
from sentence_transformers import SentenceTransformer

# Initialize
client = chromadb.Client()
collection = client.create_collection("resumes")
encoder = SentenceTransformer('all-MiniLM-L6-v2')

# Add resumes to vector database
resumes = [
    {"id": "1", "name": "Jane", "text": "Python ML engineer with 5 years experience"},
    {"id": "2", "name": "John", "text": "Frontend developer React TypeScript"},
    {"id": "3", "name": "Alice", "text": "Data scientist Python TensorFlow"},
]

for resume in resumes:
    embedding = encoder.encode(resume["text"]).tolist()
    collection.add(
        ids=[resume["id"]],
        embeddings=[embedding],
        metadatas=[{"name": resume["name"]}]
    )

# Search for similar resumes
job_description = "Looking for ML engineer with Python"
query_embedding = encoder.encode(job_description).tolist()

results = collection.query(
    query_embeddings=[query_embedding],
    n_results=2  # Get top 2 matches
)

print(results)
# Returns: Jane (0.92 similarity), Alice (0.87 similarity)
```

### IntelliHire: Current Architecture vs. Vector DB

**Current IntelliHire Approach:**
```python
# Using fuzzy string matching (rapidfuzz) instead of embeddings
from rapidfuzz import fuzz

def skills_overlap_score(jd_skills, resume_skills):
    for jd_skill in jd_skills:
        for resume_skill in resume_skills:
            score = fuzz.ratio(jd_skill, resume_skill) / 100.0
```

**With Vector Database (Enhancement):**
```python
# Convert skills and experience to embeddings
# Store in vector database
# Query for similarity

jd_embedding = encode("Python, ML, TensorFlow, 5 years experience")
similar_resumes = vector_db.query(jd_embedding, top_k=10)
```

**Trade-offs:**

| Approach | Pros | Cons |
|----------|------|------|
| **Fuzzy Matching** | Simple, fast, no ML models needed | Only catches word variations, not meaning |
| **Vector Embeddings** | Captures semantic meaning | Requires embedding model, more complex |

---

## ðŸ” 5. RAG - Retrieval Augmented Generation

### What is RAG?

**RAG = Retrieval Augmented Generation**

It's a technique that makes LLMs smarter by giving them relevant information before they answer.

### The Problem RAG Solves

**LLMs have limitations:**
1. **Knowledge cutoff** - GPT-4 doesn't know about events after training
2. **Hallucination** - Makes up facts when unsure
3. **No access to your data** - Can't see your company's documents

**RAG Solution:** Give the LLM relevant documents before asking it to answer!

### RAG Workflow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         RAG PIPELINE                             â”‚
â”‚                                                                  â”‚
â”‚  1. USER QUERY                                                   â”‚
â”‚     "Which candidates have ML experience?"                       â”‚
â”‚                          â”‚                                       â”‚
â”‚                          â–¼                                       â”‚
â”‚  2. RETRIEVE relevant documents from vector database             â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚     â”‚ Vector DB Search                          â”‚                â”‚
â”‚     â”‚ Query: "ML experience"                    â”‚                â”‚
â”‚     â”‚ Results:                                  â”‚                â”‚
â”‚     â”‚  - Resume 1: "5 years ML at Google"      â”‚                â”‚
â”‚     â”‚  - Resume 3: "Built recommendation sys"  â”‚                â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â”‚                          â”‚                                       â”‚
â”‚                          â–¼                                       â”‚
â”‚  3. AUGMENT the prompt with retrieved context                    â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚     â”‚ "Here are relevant resumes:               â”‚                â”‚
â”‚     â”‚  Resume 1: ...                            â”‚                â”‚
â”‚     â”‚  Resume 3: ...                            â”‚                â”‚
â”‚     â”‚                                           â”‚                â”‚
â”‚     â”‚  Based on these, answer: Which           â”‚                â”‚
â”‚     â”‚  candidates have ML experience?"          â”‚                â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â”‚                          â”‚                                       â”‚
â”‚                          â–¼                                       â”‚
â”‚  4. GENERATE response using LLM                                  â”‚
â”‚     "Based on the resumes, Jane (Resume 1) has 5 years of       â”‚
â”‚      ML experience at Google, and Bob (Resume 3) built          â”‚
â”‚      recommendation systems using ML techniques."                â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Analogy: Open-Book Exam

| Approach | Analogy | Quality |
|----------|---------|---------|
| **LLM alone** | Closed-book exam (memory only) | May hallucinate |
| **LLM + RAG** | Open-book exam (can reference notes) | Accurate answers |

### RAG in Code

```python
# Step 1: Index documents (one-time setup)
def index_resumes(resumes):
    for resume in resumes:
        embedding = encode(resume.text)
        vector_db.add(id=resume.id, embedding=embedding, content=resume.text)

# Step 2: Retrieve relevant documents
def retrieve(query, k=3):
    query_embedding = encode(query)
    results = vector_db.search(query_embedding, top_k=k)
    return [r.content for r in results]

# Step 3: Augment prompt with context
def generate_with_rag(user_query):
    # Retrieve relevant resumes
    relevant_docs = retrieve(user_query)
    
    # Build augmented prompt
    context = "\n\n".join(relevant_docs)
    prompt = f"""
    Here are relevant resumes:
    {context}
    
    Based on these resumes, answer the following question:
    {user_query}
    """
    
    # Generate response
    response = llm.generate(prompt)
    return response

# Usage
answer = generate_with_rag("Who has the most Python experience?")
# LLM now has actual resume data to reference!
```

### RAG for IntelliHire (Future Enhancement)

**Current State:** IntelliHire processes resumes individually, comparing each to the JD.

**With RAG:**
```
Recruiter asks: "Show me candidates similar to Jane who got hired last year"

RAG Pipeline:
1. RETRIEVE: Find Jane's resume + last year's hired candidates
2. AUGMENT: Add these to context
3. GENERATE: LLM identifies patterns and suggests matches
```

**Benefits:**
- Answer natural language questions about candidates
- Find candidates similar to successful hires
- Explain why candidates match (citing specific experience)

### RAG vs. Fine-Tuning

| Technique | What It Does | Best For |
|-----------|--------------|----------|
| **RAG** | Add knowledge at query time | Private data, changing data |
| **Fine-Tuning** | Train model on specific data | Style/format, domain expertise |
| **Both** | Fine-tune + RAG | Maximum customization |

---

## ðŸ”¤ 6. Fuzzy String Matching

### What is Fuzzy Matching?

Finding strings that are **similar but not identical**.

```
Exact Match:   "Python" == "Python"     âœ“
Fuzzy Match:   "Python" â‰ˆ "python"      âœ“ (case difference)
Fuzzy Match:   "Python" â‰ˆ "Pyhton"      âœ“ (typo)
Fuzzy Match:   "Python" â‰ˆ "Python3"     âœ“ (version)
Fuzzy Match:   "Kubernetes" â‰ˆ "K8s"     â–³ (abbreviation - harder)
```

### How IntelliHire Uses Fuzzy Matching

```python
from rapidfuzz import fuzz

# Different fuzzy matching algorithms

# 1. Simple Ratio - Character-by-character similarity
fuzz.ratio("Python", "python")  # 83 (case differs)
fuzz.ratio("Python", "Pyhton")  # 83 (one swap)

# 2. Partial Ratio - Best substring match
fuzz.partial_ratio("Python", "I know Python programming")  # 100!

# 3. Token Set Ratio - Handles word order and duplicates
fuzz.token_set_ratio(
    "machine learning engineer",
    "engineer for machine learning projects"
)  # 100! (same words, different order)

# IntelliHire skill matching
def skills_overlap_score(jd_skills, resume_skills):
    """For each JD skill, find best match in resume skills"""
    total = 0.0
    for jd_skill in jd_skills:
        best_match = 0.0
        for resume_skill in resume_skills:
            ratio = fuzz.ratio(jd_skill, resume_skill) / 100.0
            partial = fuzz.partial_ratio(jd_skill, resume_skill) / 100.0
            best_match = max(best_match, ratio, partial)
        total += best_match
    return total / len(jd_skills)
```

### Fuzzy Matching vs. Embeddings

| Fuzzy Matching | Embeddings |
|----------------|------------|
| Compares characters | Compares meaning |
| "Python" â‰ˆ "Python3" âœ“ | "Python" â‰ˆ "programming language" âœ“ |
| "Python" â‰ˆ "Snake" âœ— | "Python" â‰ˆ "coding" âœ“ |
| Fast, no ML needed | Requires embedding model |
| Good for typos/variations | Good for semantic similarity |

**IntelliHire uses fuzzy matching because:**
- Skills are usually explicit words ("Python", "React")
- Faster to implement and run
- Works well for the use case

---

## ðŸ•µï¸ 7. AI Content Detection

### What is AI Content Detection?

Determining if text was written by an AI (like ChatGPT) or a human.

### How It Works

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    AI DETECTION PATTERNS                         â”‚
â”‚                                                                  â”‚
â”‚  AI-Written Text Often Has:                                      â”‚
â”‚  â”œâ”€â”€ Generic phrases ("passionate about", "leveraged")           â”‚
â”‚  â”œâ”€â”€ Perfect grammar (too perfect!)                              â”‚
â”‚  â”œâ”€â”€ Templated structure                                         â”‚
â”‚  â”œâ”€â”€ Lack of specific details                                    â”‚
â”‚  â””â”€â”€ Overuse of certain words                                    â”‚
â”‚                                                                  â”‚
â”‚  Human-Written Text Often Has:                                   â”‚
â”‚  â”œâ”€â”€ Specific project details                                    â”‚
â”‚  â”œâ”€â”€ Personal voice/style                                        â”‚
â”‚  â”œâ”€â”€ Minor grammatical quirks                                    â”‚
â”‚  â””â”€â”€ Unique experiences                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### IntelliHire's AI Detection

```python
AI_DETECT_PROMPT = """
Estimate the likelihood that this text was generated by an LLM.
Return JSON:
{
  "ai_likelihood_percent": 0-100,
  "rationale": "explanation",
  "flags": ["pattern1", "pattern2"]
}
"""

# Example response for an AI-written resume:
{
  "ai_likelihood_percent": 75,
  "rationale": "Generic action verbs, templated structure, lacks specific metrics",
  "flags": ["buzzword-heavy", "no specific achievements", "perfect grammar"]
}

# Penalty calculation (forgiving for light AI use)
ai_pct = 75
validity_pct = 100 - int((ai_pct ** 1.2) / (100 ** 0.2))
# Result: ~65% validity (35% penalty)
```

### Why Detect AI Content?

| Concern | Reason |
|---------|--------|
| **Authenticity** | Is this person's real experience? |
| **Interview match** | Can they discuss these projects? |
| **Red flag** | Heavy AI use may indicate lack of real experience |
| **But not automatic rejection** | Light editing with AI is acceptable |

---

## ðŸ”§ 8. How IntelliHire Uses These Concepts

### Complete AI Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   INTELLIHIRE AI PIPELINE                        â”‚
â”‚                                                                  â”‚
â”‚  1. JOB DESCRIPTION PARSING (LLM)                               â”‚
â”‚     URL â†’ Fetch HTML â†’ Extract Text â†’ Gemini â†’ Structured JSON  â”‚
â”‚     Output: {title, skills, seniority, responsibilities}        â”‚
â”‚                                                                  â”‚
â”‚  2. RESUME PARSING (LLM)                                        â”‚
â”‚     PDF/DOCX â†’ Extract Text â†’ Gemini â†’ Structured JSON          â”‚
â”‚     Output: {name, skills, experience_bullets, seniority}       â”‚
â”‚                                                                  â”‚
â”‚  3. AI DETECTION (LLM)                                          â”‚
â”‚     Resume Text â†’ Gemini â†’ AI likelihood score                  â”‚
â”‚     Output: {ai_pct: 25, flags: [...]}                          â”‚
â”‚                                                                  â”‚
â”‚  4. SCORING (Fuzzy Matching + Rules)                            â”‚
â”‚     â”œâ”€â”€ Experience Similarity (fuzzy text comparison)           â”‚
â”‚     â”œâ”€â”€ Skills Overlap (fuzzy skill matching)                   â”‚
â”‚     â””â”€â”€ Trajectory Alignment (seniority mapping)                â”‚
â”‚                                                                  â”‚
â”‚  Final Score = weighted(exp + skills + trajectory)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Current vs. Enhanced Architecture

| Component | Current | With Embeddings/RAG |
|-----------|---------|---------------------|
| Skill matching | Fuzzy string matching | Semantic embedding similarity |
| Experience matching | Fuzzy text comparison | Embedding-based matching |
| Candidate search | Score all, sort | Vector DB nearest neighbor |
| Questions | Not supported | RAG-powered Q&A |

### Potential Enhancements

```python
# ENHANCEMENT 1: Embedding-based skill matching
skill_embeddings = {
    "python": encode("Python programming language"),
    "react": encode("React JavaScript frontend framework"),
}

def semantic_skill_match(jd_skill, resume_skill):
    emb1 = encode(jd_skill)
    emb2 = encode(resume_skill)
    return cosine_similarity(emb1, emb2)

# "JavaScript" would match "React" better than fuzzy matching!

# ENHANCEMENT 2: Vector DB for fast candidate search
# Instead of scoring all candidates every time:
similar_candidates = vector_db.query(
    embedding=job_description_embedding,
    filter={"seniority": "senior"},
    top_k=20
)

# ENHANCEMENT 3: RAG for natural language queries
answer = rag_pipeline(
    query="Find candidates like our last successful ML hire",
    context_sources=["resumes", "past_hires", "job_descriptions"]
)
```

---

## â“ 9. Interview Q&A

### Basic Questions

**Q: What is the difference between ML and AI?**
> "AI is the broad goal of making machines intelligent. ML is a specific approach where we let machines learn patterns from data instead of programming explicit rules. Deep Learning is a subset of ML using neural networks. LLMs are a type of deep learning specialized for language."

**Q: Explain embeddings in simple terms.**
> "Embeddings convert text into numbers (vectors) that capture meaning. Similar words get similar vectors. This lets us do math with language - we can calculate how similar two sentences are by comparing their vectors."

**Q: What is cosine similarity?**
> "It measures the angle between two vectors. If they point in the same direction (angle = 0Â°), they're identical (similarity = 1). If perpendicular (90Â°), they're unrelated (similarity = 0). It's used to compare embeddings."

### Intermediate Questions

**Q: Why use a vector database instead of regular database?**
> "Regular databases search by exact or keyword match. Vector databases find semantically similar items. For example, searching 'Python developer' in a vector DB would also return 'Python programmer' or 'software engineer with Python' because their embeddings are similar."

**Q: Explain RAG and when you would use it.**
> "RAG stands for Retrieval Augmented Generation. It improves LLM responses by first retrieving relevant documents, then including them in the prompt. Use it when you need the LLM to answer questions about your private data, or when accuracy is crucial and you want to reduce hallucinations."

**Q: How would you improve IntelliHire's matching?**
> "Currently it uses fuzzy string matching, which works well for direct skill matching. I would enhance it with:
> 1. Semantic embeddings for skill similarity ('JavaScript' matches 'React')
> 2. A vector database for fast candidate retrieval
> 3. RAG for answering natural language questions about candidates"

### Advanced Questions

**Q: Compare fuzzy matching vs. embeddings for this use case.**
> "Fuzzy matching compares character sequences - great for typos and variations ('Python' vs 'Python3'). Embeddings compare meaning - 'machine learning' would match 'ML' or 'AI/ML engineering'. For skills, fuzzy matching is often sufficient because skills are explicit terms. But for matching experience descriptions, embeddings capture semantic similarity better."

**Q: How would you scale this to 1M resumes?**
> "Key changes:
> 1. Pre-compute embeddings offline, store in vector database
> 2. Use ANN (approximate nearest neighbor) for O(log n) search
> 3. Add filters (seniority, location) to reduce search space
> 4. Cache frequent queries
> 5. Shard vector database across machines"

**Q: What are the tradeoffs of using an LLM for parsing?**
> "Pros: Handles varied formats, extracts nuanced information, no need to build custom parsers. Cons: API costs per document, latency (~1-2s per call), potential for inconsistent outputs, rate limits. Mitigations: Aggressive caching, batch processing, fallback to regex for simple fields."

---

## ðŸ“ 10. Quick Reference

### Key Terms Glossary

| Term | One-Line Definition |
|------|---------------------|
| **AI** | Machines performing human-like tasks |
| **ML** | Computers learning patterns from data |
| **LLM** | Large language model (GPT, Gemini) trained on text |
| **Embedding** | Converting text to a vector of numbers |
| **Vector** | A list of numbers representing something |
| **Cosine Similarity** | Measuring angle between vectors (similarity score) |
| **Vector Database** | Database optimized for similarity search |
| **RAG** | Adding retrieved documents to LLM prompts |
| **Fuzzy Matching** | Finding similar (not identical) strings |
| **Prompt** | Instructions given to an LLM |
| **Token** | Chunk of text (~4 characters) |
| **Temperature** | LLM creativity setting (0 = deterministic) |
| **Hallucination** | When LLM makes up false information |

### The AI Stack Visualized

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        USER QUERY                                â”‚
â”‚                "Find ML engineers with Python"                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     EMBEDDING MODEL                              â”‚
â”‚               (Convert query to vector)                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    VECTOR DATABASE                               â”‚
â”‚         (Find similar resume embeddings)                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   RAG CONTEXT BUILDER                            â”‚
â”‚         (Combine query + top resume matches)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    LLM (Gemini/GPT)                              â”‚
â”‚         (Generate natural language answer)                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        RESPONSE                                  â”‚
â”‚   "Based on the resumes, Jane and Bob are top matches..."       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### IntelliHire AI Summary

| AI Concept | How IntelliHire Uses It |
|------------|------------------------|
| **LLM (Gemini)** | Parse JDs and resumes, detect AI content |
| **Fuzzy Matching** | Skills and experience comparison |
| **Cosine Similarity** | (Available but using fuzzy) For semantic matching |
| **Vector DB** | (Future) Fast candidate retrieval |
| **RAG** | (Future) Q&A about candidates |
| **Embeddings** | (Future) Semantic skill/experience matching |

---

> ðŸ’¡ **Interview Tip**: When discussing AI, always connect concepts to **business value**:
> - "Embeddings let us find candidates the keyword search would miss"
> - "RAG reduces hallucinations, which is critical for candidate recommendations"
> - "Vector databases scale to millions of resumes with millisecond search"

Good luck with your interview! ðŸš€
